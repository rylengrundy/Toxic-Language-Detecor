<<<<<<< HEAD
---
title: "Classifying Offensive Language"
author: "Rylen Grundy"
date: "2025-04-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Section Author: Rylen Grundy
## Date: 04-23-2025
Load Libraries

```{r}
library(tidyverse)
library(textclean)
library(stringr)
library(knitr)
library(ggplot2)
library(tidytext) # Make sure to install this! - Jay
```

Read in data

```{r}
comments = read.csv("C:/Users/TheMACHINE/Downloads/train.csv", stringsAsFactors = FALSE)
# Make sure to change this to where you have the spreadsheet stored! - Jay
```

Preview Structure

```{r}
str(comments)
head(comments)
colnames(comments)
```

## Clean the text

```{r}
comments_clean = comments %>%
  mutate(
    comment_text = tolower(comment_text),                          # Make all text lowercase
    comment_text = gsub("http\\S+|www\\S+", "", comment_text),      # Remove URLs
    comment_text = gsub("[[:punct:]]", "", comment_text),           # Remove punctuation
    comment_text = gsub("\\s+", " ", comment_text),                # Replace multiple spaces with single space
    comment_text = trimws(comment_text)                             # Trim leading and trailing spaces
  )
```

## Section Author: Jay Jones
## Date: 4-30-2025

## Run Descriptives and Stats

```{r label-summary}
# Frequency and Percentages.
colSums(comments[, 3:8]) # Count of toxic comments
round(colMeans(comments[, 3:8]) * 100, 2) # Percent of comments in each category
```

```{r wordcount-summary}
# Word count Stats

comments$word_count <- str_count(comments$comment_text, "\\w+") # Add the word count

summary(comments$word_count)
```

```{r wordcount-histogram}
# Histogram Time

ggplot(comments, aes(x=word_count)) +
  geom_histogram(binwidth = 5, fill = "darkred") + labs(title = "Distribution of Comment Word Counts", x = "Words per Comment", y = "Frequency")

```

```{r top-words-function}
get_top_words_plot <- function(label_column, label_name) {
  #Filter comments for given label
  filtered_comments <- comments_clean %>%
    filter(.data[[label_column]] == 1)
  
  #Tokenize and clean
  words <- filtered_comments %>%
    select(comment_text) %>%
    unnest_tokens(word, comment_text) %>%
    anti_join(stop_words, by = "word")
  
  #Top 15 words
  top_words <- words %>%
    count(word, sort = TRUE) %>%
    slice_max(order_by = n, n = 15)
  
  #Plot
  ggplot(top_words, aes(x = reorder(word, n), y = n)) + 
    geom_col(fill = "steelblue") +
    coord_flip() +
    labs(title = paste("Top 15 Words in", label_name, "Comments"),
         x = "Word", y = "Frequency")
}
```

```{r all-top-words-plots, fig.height=6, fig.width=7}

# Toxic
get_top_words_plot("toxic", "Toxic")

# Severe Toxic
get_top_words_plot("severe_toxic", "Severe Toxic")

# Obscene
get_top_words_plot("obscene", "Obscene")

# Threat
get_top_words_plot("threat", "Threat")

# Insult
get_top_words_plot("insult", "Insult")

# Identity Hate
get_top_words_plot("identity_hate", "Identity Hate")
```


## Building Harrasment Classifier

```{r}
# Step 1: Combine labels into a single harassment label
comments_clean$harassment <- ifelse(rowSums(comments_clean[, c("toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate")]) > 0, 1, 0)

# Step 2: Filter out missing comments
comments_clean <- comments_clean[!is.na(comments_clean$comment_text), ]

# Step 3: Split data into training and test sets
set.seed(123)
library(caret)
split_index <- createDataPartition(comments_clean$harassment, p = 0.8, list = FALSE)
train_data <- comments_clean[split_index, ]
test_data <- comments_clean[-split_index, ]

# Step 4: Create TF-IDF matrix
library(text2vec)

prep_fun <- tolower
tok_fun <- word_tokenizer

it_train <- itoken(train_data$comment_text, preprocessor = prep_fun, tokenizer = tok_fun, progressbar = FALSE)
vocab <- create_vocabulary(it_train)
vectorizer <- vocab_vectorizer(vocab)

dtm_train <- create_dtm(it_train, vectorizer)
tfidf_transformer <- TfIdf$new()
dtm_train_tfidf <- tfidf_transformer$fit_transform(dtm_train)

# Step 5: Apply same process to test data
it_test <- itoken(test_data$comment_text, preprocessor = prep_fun, tokenizer = tok_fun, progressbar = FALSE)
dtm_test <- create_dtm(it_test, vectorizer)
dtm_test_tfidf <- tfidf_transformer$transform(dtm_test)

# Step 6: Train logistic regression model
library(glmnet)
model <- cv.glmnet(x = dtm_train_tfidf, y = train_data$harassment, family = "binomial", alpha = 0)

# Step 7: Predict and evaluate
pred_probs <- predict(model, dtm_test_tfidf, s = "lambda.min", type = "response")
preds <- ifelse(pred_probs > 0.5, 1, 0)

confusionMatrix(factor(preds), factor(test_data$harassment))
```
